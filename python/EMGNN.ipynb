{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Class 1: 0-19\n",
    "\n",
    "Class 2: 20-37\n",
    "\n",
    "Class 3: 38-56\n",
    "\n",
    "Class 4: 57-75\n",
    "\n",
    "Class 5: 76-105\n",
    "\n",
    "Class 6: 106 - 135\n",
    "\n",
    "Class 7: 136-164"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import seed\n",
    "from random import randint\n",
    "\n",
    "seed(1)\n",
    "\n",
    "with open(\"AllData.txt\", \"r\") as f:\n",
    "    data = []\n",
    "    data = f.read()\n",
    "    data = data.split(\"\\n\")\n",
    "\n",
    "print(len(data))\n",
    "\n",
    "with open(\"AllTestSet.txt\", \"w+\") as f:\n",
    "    for x in range(round(0.1*len(data))):\n",
    "\n",
    "        # Random value\n",
    "        value = randint(0,len(data))\n",
    "\n",
    "        # Find list in data\n",
    "        myList = data[value]\n",
    "\n",
    "        # Remove list from data\n",
    "        data.remove(myList)\n",
    "\n",
    "        # Add the list \n",
    "        f.write(myList)\n",
    "        f.write('\\n')\n",
    "        \n",
    "with open(\"AllTrainingSet.txt\", \"w+\") as f:\n",
    "    for x in range(len(data)):\n",
    "        f.write(data[x])\n",
    "        f.write(\"\\n\")\n",
    "        \n",
    "\n",
    "# Checking Data \n",
    "\n",
    "with open(\"AllTestSet.txt\", \"r\") as f:\n",
    "    data = []\n",
    "    data = f.read()\n",
    "    data = data.split(\"\\n\")\n",
    "    \n",
    "print(len(data))\n",
    "\n",
    "with open(\"AllTrainingSet.txt\", \"r\") as f:\n",
    "    data = []\n",
    "    data = f.read()\n",
    "    data = data.split(\"\\n\")\n",
    "    \n",
    "print(len(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main reason why we use sigmoid function is because it exists between (0 to 1). \n",
    "Therefore, it is especially used for models where we have to predict the probability as an output. \n",
    "Since probability of anything exists only between the range of 0 and 1, sigmoid is the right choice. \n",
    "The function is differentiable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1606, 56)\n",
      "(1606, 8)\n",
      "[[1 0 0 ... 0 0 0]\n",
      " [1 0 0 ... 0 0 0]\n",
      " [1 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 1]\n",
      " [0 0 0 ... 0 0 1]\n",
      " [0 0 0 ... 0 0 1]]\n",
      "[[-5.17578125e-03  9.91410559e-02  1.88616943e+00 ...  8.96985018e-03\n",
      "   1.74976312e+00  0.00000000e+00]\n",
      " [-6.05468750e-03  2.12881666e-02  5.92041016e-02 ...  3.23949886e-03\n",
      "   1.74200501e+00  0.00000000e+00]\n",
      " [-5.95703125e-03  1.91565622e-02  4.72412109e-02 ...  1.97707550e-03\n",
      "   1.56230509e+00  0.00000000e+00]\n",
      " ...\n",
      " [-4.78515625e-03  3.53402304e-02  1.61499023e-01 ...  1.34277344e-03\n",
      "   1.60587242e+00  0.00000000e+00]\n",
      " [-2.83203125e-03  2.97106201e-02  1.33544922e-01 ...  1.20988677e-03\n",
      "   1.64952875e+00  0.00000000e+00]\n",
      " [-1.95312500e-03  2.42376438e-02  7.30590820e-02 ...  1.16739394e-03\n",
      "   1.60739522e+00  0.00000000e+00]]\n",
      "(14427, 56)\n",
      "(14427, 8)\n"
     ]
    }
   ],
   "source": [
    "with open (\"AllTestSet.txt\", \"r\") as f:\n",
    "    data = []\n",
    "    data = f.read()\n",
    "    data = data.split(\"\\n\")\n",
    "           \n",
    "testArray = []\n",
    "for y in range(0,len(data)):\n",
    "    myList = []\n",
    "    myList = data[y].split(\",\")\n",
    "    for x in range(len(myList)-1):\n",
    "        myList[x] = float(myList[x])\n",
    "    \n",
    "    # removes the '' at the end of each list\n",
    "    myList = myList[1:len(myList)-1]\n",
    "    testArray.append(myList)\n",
    "    # convert the data set from a list of strings to a list of ints \n",
    "\n",
    "labelArray = []\n",
    "\n",
    "for x in range(len(testArray)):\n",
    "    if (testArray[x] != []):\n",
    "        cls = testArray[x][len(testArray[x])-1]\n",
    "        labelClass = []\n",
    "        \n",
    "        for y in range(0, 8):\n",
    "            if(y == int(cls)):\n",
    "                labelClass.append(1)\n",
    "            else:\n",
    "                labelClass.append(0)\n",
    "        labelArray.append(labelClass)\n",
    "        testArray[x].pop()\n",
    "\n",
    "for x in range(len(testArray) - len(labelArray)):\n",
    "    testArray.remove([])\n",
    "\n",
    "testArray = np.asarray(testArray)\n",
    "labelArray = np.asarray(labelArray)\n",
    "\n",
    "print(testArray.shape)\n",
    "print(labelArray.shape)\n",
    "        \n",
    "# Training Set\n",
    "\n",
    "with open (\"AllTrainingSet.txt\", \"r\") as f:\n",
    "    data = []\n",
    "    data = f.read()\n",
    "    data = data.split(\"\\n\")\n",
    "           \n",
    "trainingArray = []\n",
    "for y in range(0,len(data)):\n",
    "    myList = []\n",
    "    myList = data[y].split(\",\")\n",
    "    for x in range(len(myList)-1):\n",
    "        myList[x] = float(myList[x])\n",
    "\n",
    "    myList = myList[1:len(myList)-1]\n",
    "    trainingArray.append(myList)\n",
    "    # convert the data set from a list of strings to a list of ints \n",
    "\n",
    "\n",
    "trainLabArray = []\n",
    "\n",
    "for x in range(len(trainingArray)-1):\n",
    "    if (trainingArray[x] != []):\n",
    "        cls = trainingArray[x][len(trainingArray[x])-1]\n",
    "        labelClass = []\n",
    "        \n",
    "        for y in range(0, 8):\n",
    "            if(y == int(cls)):\n",
    "                labelClass.append(1)\n",
    "            else:\n",
    "                labelClass.append(0)\n",
    "        trainLabArray.append(labelClass)\n",
    "        trainingArray[x].pop()\n",
    "\n",
    "for x in range(len(trainingArray) - len(trainLabArray)):\n",
    "    trainingArray.remove([])\n",
    "\n",
    "trainingArray = np.asarray(trainingArray)\n",
    "trainLabArray = np.asarray(trainLabArray)\n",
    "print(trainLabArray)\n",
    "print(trainingArray)\n",
    "\n",
    "print(trainingArray.shape)\n",
    "print(trainLabArray.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 14427 samples, validate on 1606 samples\n",
      "Epoch 1/15\n",
      "14427/14427 [==============================] - 1s 77us/sample - loss: 0.4620 - accuracy: 0.8761 - val_loss: 0.2576 - val_accuracy: 0.9278\n",
      "Epoch 2/15\n",
      "14427/14427 [==============================] - 1s 38us/sample - loss: 0.2501 - accuracy: 0.9281 - val_loss: 0.2513 - val_accuracy: 0.9197\n",
      "Epoch 3/15\n",
      "14427/14427 [==============================] - 1s 40us/sample - loss: 0.2457 - accuracy: 0.9282 - val_loss: 0.2299 - val_accuracy: 0.9296\n",
      "Epoch 4/15\n",
      "14427/14427 [==============================] - 1s 44us/sample - loss: 0.2314 - accuracy: 0.9321 - val_loss: 0.2315 - val_accuracy: 0.9346\n",
      "Epoch 5/15\n",
      "14427/14427 [==============================] - 1s 42us/sample - loss: 0.2220 - accuracy: 0.9356 - val_loss: 0.2605 - val_accuracy: 0.9147\n",
      "Epoch 6/15\n",
      "14427/14427 [==============================] - 1s 44us/sample - loss: 0.2301 - accuracy: 0.9335 - val_loss: 0.2209 - val_accuracy: 0.9384\n",
      "Epoch 7/15\n",
      "14427/14427 [==============================] - 1s 39us/sample - loss: 0.2273 - accuracy: 0.9319 - val_loss: 0.2419 - val_accuracy: 0.9265\n",
      "Epoch 8/15\n",
      "14427/14427 [==============================] - 1s 45us/sample - loss: 0.2332 - accuracy: 0.9310 - val_loss: 0.2123 - val_accuracy: 0.9408\n",
      "Epoch 9/15\n",
      "14427/14427 [==============================] - 1s 46us/sample - loss: 0.2304 - accuracy: 0.9324 - val_loss: 0.2044 - val_accuracy: 0.9421\n",
      "Epoch 10/15\n",
      "14427/14427 [==============================] - 1s 45us/sample - loss: 0.2317 - accuracy: 0.9303 - val_loss: 0.2327 - val_accuracy: 0.9346\n",
      "Epoch 11/15\n",
      "14427/14427 [==============================] - 1s 37us/sample - loss: 0.2093 - accuracy: 0.9371 - val_loss: 0.2120 - val_accuracy: 0.9328\n",
      "Epoch 12/15\n",
      "14427/14427 [==============================] - 1s 50us/sample - loss: 0.2114 - accuracy: 0.9392 - val_loss: 0.2232 - val_accuracy: 0.9384\n",
      "Epoch 13/15\n",
      "14427/14427 [==============================] - 1s 40us/sample - loss: 0.2101 - accuracy: 0.9376 - val_loss: 0.2481 - val_accuracy: 0.9253\n",
      "Epoch 14/15\n",
      "14427/14427 [==============================] - 1s 45us/sample - loss: 0.2244 - accuracy: 0.9366 - val_loss: 0.2428 - val_accuracy: 0.9309\n",
      "Epoch 15/15\n",
      "14427/14427 [==============================] - 1s 40us/sample - loss: 0.2532 - accuracy: 0.9250 - val_loss: 0.2357 - val_accuracy: 0.9278\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x63a0ea490>"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras import layers\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "\n",
    "# Layer represents the number of inputs \n",
    "model.add(layers.Dense(56))\n",
    "\n",
    "# activation layer connects each input node to all the neurons in the hidden layer\n",
    "# Sigmoid is always before softmax (sigmoid = graph plateus)\n",
    "model.add(layers.Dense(28, activation='sigmoid'))\n",
    "\n",
    "# softmax layer essentially gives a probability value to each of the outputs (all add up to 1)\n",
    "model.add(layers.Dense(8, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(0.01),\n",
    "    loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit(trainingArray, trainLabArray, epochs=15, batch_size=56, validation_data=(testArray,labelArray))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58\n"
     ]
    }
   ],
   "source": [
    "with open (\"AllData.txt\", \"r\") as f:\n",
    "    data = []\n",
    "    data = f.read()\n",
    "    data = data.split(\"\\n\")\n",
    "           \n",
    "testArray = []\n",
    "for y in range(0,len(data)):\n",
    "    myList = []\n",
    "    myList = data[y].split(\",\")\n",
    "    for x in range(len(myList)-1):\n",
    "        myList[x] = float(myList[x])\n",
    "    \n",
    "    # removes the '' at the end of each list\n",
    "    myList = myList[1:len(myList)-1]\n",
    "    testArray.append(myList)\n",
    "    # convert the data set from a list of strings to a list of ints \n",
    "\n",
    "labelArray = []\n",
    "\n",
    "for x in range(len(testArray)):\n",
    "    if (testArray[x] != []):\n",
    "        cls = testArray[x][len(testArray[x])-1]\n",
    "        labelClass = []\n",
    "        \n",
    "        for y in range(0, 8):\n",
    "            if(y == int(cls)):\n",
    "                labelClass.append(1)\n",
    "            else:\n",
    "                labelClass.append(0)\n",
    "        labelArray.append(labelClass)\n",
    "        testArray[x].pop()\n",
    "\n",
    "for x in range(len(testArray) - len(labelArray)):\n",
    "    testArray.remove([])\n",
    "\n",
    "testArray = np.asarray(testArray)\n",
    "\n",
    "print(len(testArray))\n",
    "labelArray = np.asarray(labelArray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictions shape: [[8.69933283e-05 6.83128193e-04 1.82545659e-06 1.64387639e-05\n",
      "  5.73887974e-07 8.73768926e-01 4.16829107e-06 1.25438064e-01]\n",
      " [1.58672119e-04 8.51560908e-04 1.48070842e-06 1.54511145e-05\n",
      "  2.72232683e-07 8.86039555e-01 9.02356351e-06 1.12924039e-01]\n",
      " [2.13914886e-04 9.49798559e-04 1.33334481e-06 1.49728030e-05\n",
      "  1.87663517e-07 8.91702831e-01 1.32488467e-05 1.07103772e-01]\n",
      " [2.16870976e-04 9.54575371e-04 1.32695152e-06 1.49513435e-05\n",
      "  1.84485387e-07 8.91955435e-01 1.34845286e-05 1.06843069e-01]\n",
      " [2.16848770e-04 9.54530551e-04 1.32694731e-06 1.49509106e-05\n",
      "  1.84498006e-07 8.91954303e-01 1.34831744e-05 1.06844462e-01]\n",
      " [2.16048982e-04 9.62932536e-04 1.32677951e-06 1.47877308e-05\n",
      "  1.82166971e-07 8.90827477e-01 1.36863182e-05 1.07963480e-01]\n",
      " [1.96984649e-04 9.44913307e-04 1.36757717e-06 1.46840766e-05\n",
      "  1.99219883e-07 8.87499392e-01 1.25114793e-05 1.11329988e-01]\n",
      " [1.94687309e-04 9.19928541e-04 1.37771065e-06 1.50807045e-05\n",
      "  2.10143000e-07 8.89689207e-01 1.17941281e-05 1.09167725e-01]\n",
      " [2.04390177e-04 9.39837133e-04 1.35367054e-06 1.49420648e-05\n",
      "  1.96554751e-07 8.90215933e-01 1.26447194e-05 1.08610719e-01]\n",
      " [7.46816397e-03 4.13443111e-02 6.43722597e-05 5.49404765e-04\n",
      "  9.71434133e-07 6.81824744e-01 1.55613467e-04 2.68592328e-01]\n",
      " [2.51723696e-02 7.36779273e-01 5.94243975e-05 3.41574632e-04\n",
      "  4.52974837e-06 2.10101709e-01 1.89871298e-05 2.75220517e-02]\n",
      " [2.31051594e-02 7.73346007e-01 6.51847658e-05 2.66731193e-04\n",
      "  2.74482841e-06 1.79539233e-01 2.08414967e-05 2.36540977e-02]\n",
      " [1.88795086e-02 9.07386065e-01 6.96912248e-05 5.79730950e-05\n",
      "  9.68540235e-08 6.55648261e-02 4.78581242e-05 7.99399521e-03]\n",
      " [1.75220873e-02 9.06806171e-01 7.62520067e-05 6.14527817e-05\n",
      "  1.16219034e-07 6.70980588e-02 4.25821236e-05 8.39336682e-03]\n",
      " [1.16523821e-02 8.94028544e-01 1.16698073e-04 8.06829776e-05\n",
      "  3.09759486e-07 8.24518874e-02 2.38849407e-05 1.16457157e-02]\n",
      " [5.04901353e-03 4.22703594e-01 1.04048995e-05 5.45534249e-06\n",
      "  3.52575924e-08 5.31077981e-01 1.28079584e-04 4.10253853e-02]\n",
      " [5.05545596e-03 4.20298010e-01 1.01654368e-05 5.33711545e-06\n",
      "  3.41319080e-08 5.33518493e-01 1.30463013e-04 4.09819670e-02]\n",
      " [5.05626248e-03 4.20307934e-01 1.01641936e-05 5.33673710e-06\n",
      "  3.41216797e-08 5.33510208e-01 1.30494955e-04 4.09796573e-02]\n",
      " [5.05519658e-03 4.20049846e-01 1.01610822e-05 5.33582579e-06\n",
      "  3.41192354e-08 5.33746839e-01 1.30578002e-04 4.10020351e-02]\n",
      " [4.98764031e-03 4.04255539e-01 9.96500967e-06 5.27820339e-06\n",
      "  3.39561694e-08 5.48225164e-01 1.35702285e-04 4.23807092e-02]\n",
      " [5.05603291e-03 4.20252383e-01 1.01635333e-05 5.33653338e-06\n",
      "  3.41210260e-08 5.33561051e-01 1.30513115e-04 4.09844592e-02]\n",
      " [5.00822393e-03 4.08943802e-01 1.00241250e-05 5.29589170e-06\n",
      "  3.40083517e-08 5.43928802e-01 1.34169037e-04 4.19696309e-02]\n",
      " [5.05609717e-03 4.20267969e-01 1.01637161e-05 5.33658340e-06\n",
      "  3.41211503e-08 5.33546746e-01 1.30508124e-04 4.09831107e-02]\n",
      " [5.05625317e-03 4.20305789e-01 1.01641699e-05 5.33671482e-06\n",
      "  3.41214736e-08 5.33512056e-01 1.30496162e-04 4.09798361e-02]\n",
      " [5.05628530e-03 4.20313478e-01 1.01642690e-05 5.33674620e-06\n",
      "  3.41215411e-08 5.33505023e-01 1.30493558e-04 4.09791619e-02]\n",
      " [5.05628763e-03 4.20313478e-01 1.01642690e-05 5.33674620e-06\n",
      "  3.41216051e-08 5.33505023e-01 1.30493689e-04 4.09792028e-02]\n",
      " [5.07574296e-03 4.20789897e-01 1.01728638e-05 5.35101753e-06\n",
      "  3.43559954e-08 5.32764912e-01 1.31318680e-04 4.12226468e-02]\n",
      " [5.06515941e-03 4.20529425e-01 1.01681917e-05 5.34325818e-06\n",
      "  3.42283961e-08 5.33168614e-01 1.30870380e-04 4.10903618e-02]\n",
      " [5.01372851e-03 4.09928113e-01 1.00366460e-05 5.30043326e-06\n",
      "  3.40352457e-08 5.43004632e-01 1.33919995e-04 4.19042893e-02]\n",
      " [5.01711480e-03 4.10972416e-01 1.00494844e-05 5.30346870e-06\n",
      "  3.40315580e-08 5.42067289e-01 1.33516049e-04 4.17943113e-02]\n",
      " [4.97175660e-03 4.00613725e-01 9.91861725e-06 5.26442864e-06\n",
      "  3.39188837e-08 5.51554084e-01 1.36925039e-04 4.27082926e-02]\n",
      " [5.05621126e-03 4.20275003e-01 1.01638088e-05 5.33666798e-06\n",
      "  3.41223405e-08 5.33538878e-01 1.30510685e-04 4.09838930e-02]\n",
      " [5.05622802e-03 4.20299679e-01 1.01641044e-05 5.33669072e-06\n",
      "  3.41214488e-08 5.33517778e-01 1.30498054e-04 4.09803577e-02]\n",
      " [5.43132192e-03 4.29109544e-01 1.03213897e-05 5.60822900e-06\n",
      "  3.87798451e-08 5.19521773e-01 1.46804363e-04 4.57745753e-02]\n",
      " [5.19249914e-03 4.23599243e-01 1.02234035e-05 5.43625038e-06\n",
      "  3.57794256e-08 5.28360069e-01 1.36319053e-04 4.26961370e-02]\n",
      " [1.95779698e-03 6.79820627e-02 3.20336653e-06 2.26184466e-06\n",
      "  1.79467001e-08 8.48512352e-01 3.16309772e-04 8.12259391e-02]\n",
      " [4.57627932e-03 3.19519401e-01 8.76601644e-06 4.90067941e-06\n",
      "  3.29908048e-08 6.24712169e-01 1.68637838e-04 5.10098934e-02]\n",
      " [1.86911982e-03 6.00244887e-02 2.92836148e-06 2.15351520e-06\n",
      "  1.78619182e-08 8.50124717e-01 3.42742715e-04 8.76338333e-02]\n",
      " [1.41503969e-02 3.04967701e-01 7.86045712e-06 9.48282377e-06\n",
      "  3.56064504e-07 2.57615507e-01 1.65209034e-03 4.21596557e-01]\n",
      " [3.42933601e-03 2.24042274e-02 1.19643300e-06 2.33401488e-06\n",
      "  1.52727452e-07 2.08923399e-01 3.80901620e-03 7.61430323e-01]\n",
      " [3.39323957e-03 2.21248381e-02 1.18806679e-06 2.31583817e-06\n",
      "  1.50661904e-07 2.10826829e-01 3.80396121e-03 7.59847462e-01]\n",
      " [3.41716851e-03 2.22898964e-02 1.21438381e-06 2.36757455e-06\n",
      "  1.46952431e-07 2.21993506e-01 3.73356091e-03 7.48562098e-01]\n",
      " [2.69842148e-03 6.57953368e-03 9.75858484e-07 3.82714234e-06\n",
      "  3.09377697e-08 7.50680447e-01 1.03330589e-03 2.39003435e-01]\n",
      " [6.70818728e-04 3.60160694e-03 6.04047216e-07 1.39306121e-06\n",
      "  2.93801494e-09 9.65107501e-01 1.16903357e-04 3.05012129e-02]\n",
      " [3.40083311e-03 2.24197526e-02 1.20675941e-06 2.33496189e-06\n",
      "  1.48775555e-07 2.16629103e-01 3.76664149e-03 7.53780007e-01]\n",
      " [3.15515185e-03 3.19911130e-02 1.79992207e-06 2.60465640e-06\n",
      "  8.58447464e-08 4.59399730e-01 2.36865552e-03 5.03080904e-01]\n",
      " [3.39129451e-03 2.79915258e-02 1.54083580e-06 2.56199928e-06\n",
      "  1.15939116e-07 3.31998914e-01 3.06886737e-03 6.33545220e-01]\n",
      " [1.61369762e-03 5.23968041e-02 1.12674979e-05 1.04932974e-06\n",
      "  1.05731361e-08 9.01212156e-01 7.40502914e-03 3.73599231e-02]\n",
      " [3.08613438e-04 3.27671692e-03 4.24295740e-06 1.02310867e-06\n",
      "  4.52639437e-09 9.86805677e-01 4.64434910e-04 9.13921092e-03]\n",
      " [1.88114165e-04 1.63838034e-03 3.94088602e-06 1.60652019e-06\n",
      "  1.40508083e-09 9.89587188e-01 1.47880090e-03 7.10195163e-03]\n",
      " [1.94860040e-04 1.53757911e-03 3.74049364e-06 1.69117084e-06\n",
      "  1.03020981e-09 9.89556015e-01 2.01123324e-03 6.69485657e-03]\n",
      " [7.12007401e-04 4.39021690e-03 3.08162521e-06 9.17703517e-07\n",
      "  1.52674695e-09 9.85821664e-01 1.37123652e-03 7.70089822e-03]\n",
      " [6.91933208e-04 4.14660154e-03 2.58511159e-06 9.41913754e-07\n",
      "  1.54693791e-09 9.85705376e-01 1.04315660e-03 8.40938650e-03]\n",
      " [6.65543368e-04 3.79808224e-03 1.96939686e-06 9.89259320e-07\n",
      "  1.60211711e-09 9.85065401e-01 6.87918975e-04 9.78003256e-03]\n",
      " [6.35452569e-04 3.47145903e-03 1.50394828e-06 1.03117429e-06\n",
      "  1.63677838e-09 9.84231293e-01 4.52395005e-04 1.12068728e-02]\n",
      " [6.61858881e-04 3.91389104e-03 3.02929448e-06 9.90247941e-07\n",
      "  1.22947252e-09 9.86363947e-01 1.69973006e-03 7.35657942e-03]\n",
      " [2.22064860e-04 1.58209132e-03 3.53398605e-06 1.68923032e-06\n",
      "  8.17543033e-10 9.89212751e-01 2.54953350e-03 6.42844848e-03]\n",
      " [2.01953721e-04 1.81485643e-03 3.99391183e-06 1.50639198e-06\n",
      "  1.67461178e-09 9.89354014e-01 1.24912697e-03 7.37454649e-03]]\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(testArray)\n",
    "\n",
    "print('predictions shape:', predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
