---
layout: page
title: Prior Works
permalink: /previousworks/
---
<html>
  <body>
    <p>There have been many previous designs revolved around determining the best machine learning model to predict gestures from sEMG signal analysis. The many different models and algorithms include: gated recurrent unit (GRU), stacked sparse auto encoders (SSAE), latent Dirichlet allocation (LDA), convolutional neural networks (CNN), and artificial neural networks (ANN). Based upon these documented results, we concluded that the best model for our system would be a supervised ANN with a time-domain feature extracted dataset. The proposed ANN would consist of a single main hidden layer and a total of 6 features will be extracted from all 8 channels of each EMG dataset. Given a strong dataset, the ANN will be able to predict and differentiate between the different gestures prior to gesture completion, demonstrating real-time signal interpretation.
      <br><br>All previous designs consistently looked to differentiate from, essentially, the same gesture set. The main gestures include iterations of wrist flexion (waves), multiple finger taps, closed hand, and open hand.
      <center><figure>
          <img class = "size" src="https://miro.medium.com/max/2604/1*9uvS5j1EZXdQuIoqyb5syA.jpeg" style="max-width:50%;">
          <center><figcaption>An example gesture set of a Myo Armband-based paper</figcaption></center>
      </figure></center>
      The overlying theme across all these gesture sets is the requirement of every finger to stimulate muscle activity. Whether a finger is voluntarily curled, straightened, or flexed, it produces a noticeable change within the sEMG signal. Therefore, these gestures can be considered dissimilar and more easily differentiable. Single-finger gestures, however, were not covered in any relevant literatures on the Myo Armband. These gestures are much more difficult to identify due to the lack of overall signal strength and activity. We want to emulate typing movements; therefore, our gesture set was defined by the standard motions involved when typing on a QWERTY keyboard. Additionally, since there are no previous works involving the recognition of these gestures, the method of handling and sampling these single-finger gestures were all unique to our design.
    <br><br>Interfacing between the Myo Armband and personal devices have traditionally revolved around the implementation of whole-hand gestures. This can be difficult considering the unnatural and slow-paced nature of performing these sets. By creating a design revolved around user experience, our application translates natural typing motion into input with a single Myo Armband. The video below demonstrates an example of previous designs for EMG-based user input.
      <iframe width="560" height="315" src="https://www.youtube.com/embed/w5zwfulRW9o" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
    </p>
    <h3>Main Research Papers</h3>
    <h4><i>Multiday EMG Classification of Hand Motions with Deep Learning Techniques</i></h4>
    <p>The experiment detailed within this paper looks to determine what neural network would be best suited for EMG predictions for the purposes of real-time simulation. There were seven total subjects and each of their data were independently processed using four methods of machine learning: linear determinant analysis (LDA) with handcrafted features, unsupervised stacked sparse auto encoders (SSAE), SSAE with handcrafted features, and an unsupervised convolutional neural network (CNN). The data was filtered using a third order Butterworth high-pass filter and a sliding window was implemented to account for the time domain features: mean average value (MAV), waveform length (WL), slope-sign change (SSC), and zero-change (ZC). Data was collected over a course of 15 days with four different sets of data: within-session, between-session, between pairs of days, and leave-one-out between days. Ultimately, the research concluded that the unsupervised CNN with 3 layers (input, hidden, and output with fully connected (FC) layers and a softmax) produced much more precise and accurate results in comparison to the other algorithms; the SSAE with handcrafted features produced the next best results. Therefore, within our model, we decided to implement a similar model of CNN with the addition of the handcrafted time-domain features</p>
    <h4><i>Real-Time Surface EMG Pattern Recognition for Hand Gestures Based on an Artificial Neural Networks</i></h4>
    <p>The main goal of this paper was to implement a neural network to demonstrate a real-time sEMG analysis that attempts to recognize a gesture prior to completion. Although similar to the goal in the first literature, this design utilized a feed-forward artificial neural network (ANN) along with 7 time-domain handcrafted features to attempt EMG gesture prediction. The 7 features included MAV, WL, SSC, root mean squared (RMS), Activity Hjorth Parameter (AHP), Mobility Hjorth Parameter (MHP), and Complex Hjorth Parameter (CHP). Five dissimilar gestures consisting of whole-hand movements were predicted at a 98.7% accuracy. The paper also delves into the implementation of other iterations of neural network models (unsupervised models, SVM, LDA, etc.) and concludes that the ANN was the best-fit model for real-time EMG processing. Our model was closely aligned to the one presented due to its high mark of accuracy and overall relevancy with the conclusions described in other works.</p>
    <h4><i>Comparison of six electromyography acquisition setups on hand movement classification tasks</i></h4>
    <p>This paper explains the basis for the benchmark Myo Armband EMG datasets from the NinaPro EMG Database. The main premise was to classify multiple methods of EMG signal extraction with systems ranging from a few hundred dollars to several thousands of dollars. Although the NinaPro DB5 dataset consists of variations of single-finger extensions EMG sets, these were gathered using two Myo Armbands and a CyberGlove with 22 points of haptic feedback. Due to the implementation of a single Myo Armband and a machine learning model, our single-finger gesture recognition design remains unique.</p>
    <h3>Other Related Papers</h3>
    <p>
    </p>
  </body>
</html>
