---
layout: page
title: About
permalink: /about/
---

<html>
  <body>
    <p>The most recent wave of technology has been revolved around the concept of automation and improving quality of life. Neural networks and machine learning models have paved the pathway for such innovations and the IoT market is growing larger by the year. We decided to implement a machine learning model to the Myo Armband to bring back the product with a more modern application. There have been many research papers performed around dissimilar gesture recognition from the Myo Armband, and more recently, experiments have attempted to implement a real-time feature to the product through neural networks. The novelty behind our own design is the inclusion of single-finger gestures in the gesture-recognition algorithm at a real-time rate. The goal of our design is to implement single-finger and whole-hand gesture recognition to demonstrate user expression within personal devices. Key features to fully demonstrate user expression include the ease of typing and basic click/pointer events such as the click of a cursor.</p>
      <h3>Overall Project Goal</h3>
      <p>Create a gesture recognition algorithm for purposes of interfacing EMG sensors with personal devices. More specifically, we aim to demonstrate the ability to differentiate between single-finger gestures and correspond these movements to natural human-computer interaction.</p>
      <h3>Specific Aims</h3>
      <p><ul>
        <li>Propose a specific set of gestures to recognize based on trade-offs between accuracy and ease</li>
        <li>Develop a feature extraction algorithm and neural network implementation</li>
        <li>Demonstrate translation of gesture recognition algorithm via Android application</li>
      </ul></p>
      <h3>Implications and Today's Status</h3>
      <p>Currently, there are no products that can adequately translate mimimal human motion into specific actions without environment-specific equipment or inefficient amounts of interactive hardware. Currently, the Tap Strap is the only commercially available product that is able to read single-finger gestures, but it requires the usage of 5 accelerometers attached to each finger. The expectation of this project is to demonstrate the capability of utilizing one Myo Armband to distinctively evaluate single-finger gestures at a real-time speed. This will allow for a new method of human interaction with personal devices, increasing the ease and efficiency of daily tasks.</p>
      <center><figure>
          <img class = "size" src="https://cnet1.cbsistatic.com/img/00XQEmFzx7Xio51Kw8V0E4zo_oE=/2017/11/21/b97d2dc7-e471-47b8-a2e0-9091b2d26bcd/fl-tapkeyboard-cnetstill.jpg" style="max-width:50%;">
          <center><figcaption>The Tap Strap translates the change in accelerometer readings to user input</figcaption></center>
        </figure></center>
  <h3>Novelty</h3>
  <p>Since the Myo Armband's release, there have not been iterations of Myo Armband-based applications involving the interpretation of single-finger gestures. Due to high similarities in sEMG signal output (especially with a commercially available product like the Myo Armband), these gestures become difficult for a neural network to distinguish. Our robust methods of cleaning and classifying allow for strong feature-extracted datasets that ultimately lead to a strong classifier to differentiate between these single-finger gestures. The ability to recognize subtle human movements can then be translated into a platform for human-computer interaction with personal devices and IoT. Traditional methods of gathering sEMG data required inconvenient amounts of hardware, making any form of interaction unfeasible. The ability to recognize and register natural typing movements with the low-budget and mobile Myo Armband brings sEMG signal analysis into greater perspective.</p>
  </body>
</html>
